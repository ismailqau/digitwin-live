# XTTS-v2 Service Docker Compose
# Supports GPU, CPU, and Apple Silicon deployments

version: '3.8'

services:
  # GPU version (Linux with NVIDIA GPU)
  xtts-gpu:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: xtts-gpu
    ports:
      - '8000:8000'
    environment:
      - XTTS_GPU_ENABLED=true
      - XTTS_MODEL_NAME=tts_models/multilingual/multi-dataset/xtts_v2
      - XTTS_MAX_TEXT_LENGTH=500
      - PORT=8000
      - HOST=0.0.0.0
    volumes:
      - ./models:/app/models
      - ./cache:/app/cache
      - ./logs:/app/logs
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    profiles:
      - gpu

  # CPU version (Windows, Linux without GPU)
  xtts-cpu:
    build:
      context: .
      dockerfile: Dockerfile.cpu
    container_name: xtts-cpu
    ports:
      - '8000:8000'
    environment:
      - XTTS_GPU_ENABLED=false
      - XTTS_MODEL_NAME=tts_models/multilingual/multi-dataset/xtts_v2
      - XTTS_MAX_TEXT_LENGTH=500
      - PORT=8000
      - HOST=0.0.0.0
    volumes:
      - ./models:/app/models
      - ./cache:/app/cache
      - ./logs:/app/logs
    restart: unless-stopped
    profiles:
      - cpu

  # Apple Silicon M1/M2/M3 optimized version
  xtts-m1:
    build:
      context: .
      dockerfile: Dockerfile.m1
    container_name: xtts-m1
    ports:
      - '8000:8000'
    environment:
      - XTTS_GPU_ENABLED=false
      - XTTS_MODEL_NAME=tts_models/multilingual/multi-dataset/xtts_v2
      - XTTS_MAX_TEXT_LENGTH=500
      - PORT=8000
      - HOST=0.0.0.0
      - PYTORCH_ENABLE_MPS_FALLBACK=1
      - OMP_NUM_THREADS=8
    volumes:
      - ./models:/app/models
      - ./cache:/app/cache
      - ./logs:/app/logs
    restart: unless-stopped
    profiles:
      - m1

  # Development version with hot reload
  xtts-dev:
    build:
      context: .
      dockerfile: Dockerfile.cpu
    container_name: xtts-dev
    ports:
      - '8000:8000'
    environment:
      - XTTS_GPU_ENABLED=false
      - XTTS_MODEL_NAME=tts_models/multilingual/multi-dataset/xtts_v2
      - XTTS_MAX_TEXT_LENGTH=500
      - PORT=8000
      - HOST=0.0.0.0
    volumes:
      - ./models:/app/models
      - ./cache:/app/cache
      - ./logs:/app/logs
      - .:/app # Mount source code for development
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    restart: unless-stopped
    profiles:
      - dev
